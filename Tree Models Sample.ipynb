{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zri = pd.read_csv('df2.csv', index_col=0)\n",
    "zri['MortDeliq30-89'] = zri['MortDeliq30-89'].fillna(zri['MortDeliq30-89'].mean())\n",
    "zri['MortDeliq90'] = zri['MortDeliq90'].fillna(zri['MortDeliq90'].mean())\n",
    "zri['education'] = zri['high_school_diploma'] + zri['associates_degree'] * 2 + zri['bachelors_degree'] * 3 +zri['masters_degree']* 4\n",
    "zri['AGIncome'] = (zri['AGIncome']*1000)/zri['total_pop']\n",
    "zri['TotIncome'] = (zri['TotIncome']*1000)/zri['total_pop']\n",
    "zri['SalariesWages'] = (zri['SalariesWages']*1000)/zri['total_pop']\n",
    "zri['NumUnemply'] =(zri['NumUnemply']*1000)/zri['total_pop']\n",
    "zri['TotTaxes'] = (zri['TotTaxes']*1000)/zri['total_pop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = [ 'City', 'State', 'Metro', 'CountyName', 'SizeRank',\n",
    "       'Year-Month', 'value', 'Month', 'Year', 'year',  'geo_id', 'FIPSCode',\n",
    "          'high_school_diploma', 'associates_degree', 'bachelors_degree',\n",
    "       'masters_degree' , 'Employed', 'Unemployed',\n",
    "          'AGIncome','TotIncome', 'SalariesWages', 'Labor\\nForce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(zri.loc[zri['Year']==2015].rename(columns = {'value' : 'value_2015'}),\n",
    "                 zri.loc[zri['Year']==2016][['ZIPCODE', 'Month','value']],\n",
    "                 how = 'left', on = ['ZIPCODE', 'Month'])\n",
    "test = pd.merge(zri.loc[zri['Year']==2018].rename(columns = {'value' : 'value_2018'}),\n",
    "                zri.loc[zri['Year']==2019][['ZIPCODE', 'Month','value']],\n",
    "                how = 'left', on = ['ZIPCODE', 'Month'])\n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "X_train = train.drop(columns = dropped)\n",
    "X_test = test.drop(columns = dropped)\n",
    "y_train = train['value']\n",
    "y_test = test['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X,\n",
    "#     y,\n",
    "#     test_size=0.3,\n",
    "#     random_state=0)\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "The train set R^2 is 0.994\n",
      "The test set R^2 is 0.973\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingRegressor()\n",
    "\n",
    "gbm.set_params(n_estimators = 1000, \n",
    "            learning_rate = .1, #.3,\n",
    "            max_depth = 2, #2,\n",
    "            min_samples_leaf = 3)\n",
    "\n",
    "gbm.fit(X_train,y_train)\n",
    "\n",
    "print('-'*50)\n",
    "print(\"The train set R^2 is %.3f\" %(gbm.score(X_train, y_train)))\n",
    "print(\"The test set R^2 is %.3f\" %(gbm.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_estimator: \n",
    "\n",
    "x = np.logspace(1, 3, 100)\n",
    "x = x.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'n_estimators':x,\n",
    "           'learning_rate': [.3,.2,0.1],\n",
    "            'max_depth':[1,2,3],\n",
    "            'min_samples_leaf':[3]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator= gbm, param_grid= param_grid)\n",
    "%time grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost - Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted(zip(X.columns, gbm.feature_importances_), key=lambda t:t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe of the top 12 features in feature importance and graphing the features\n",
    "\n",
    "d = {'Features': ['Overall Quality', 'GrLivArea', 'TotalBsmtSF','Neighborhood','Total Bathrooms','Curb Appeal', \\\n",
    "                 'YearBuilt','Fireplaces','LotArea','Overall Condition','HeatingQC','Central Air'], \\\n",
    "     'Scores': [0.4389, 0.1795,0.1071,0.0822,0.0589,0.0401,0.0175,0.0153,0.0149,0.0091,0.0052,0.0040]}\n",
    "important_features = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = important_features.rename(columns={'Scores': \"Coefficients\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Coefficients', y='Features', data=important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost - Plotting Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the actual values vs. the predicted values\n",
    "\n",
    "gbm_predicted = pd.DataFrame(gbm.predict(X))\n",
    "gbm_predicted = gbm_predicted.rename(columns={0: \"Predicted\"})\n",
    "gbm_predicted_actual = pd.concat([gbm_predicted, g], axis=1, sort=False)\n",
    "sns.scatterplot(x=gbm_predicted_actual['SalePrice'], y=gbm_predicted_actual['Predicted'], data=gbm_predicted_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the actual values vs. absolute residuals \n",
    "\n",
    "gbm_residuals = pd.DataFrame(y - gbm.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_residuals = gbm_residuals.rename(columns={\"SalePrice\": \"Residual Values\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = clean_df[['SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm_resid = pd.concat([gbm_residuals, f], axis=1, sort=False)\n",
    "sns.scatterplot(x=gbm_resid['SalePrice'], y=gbm_resid['Residual Values'], data=gbm_resid).set_title \\\n",
    "('Gradient Boost Residuals Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-26e1885d6754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model1 = XGBRegressor()\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The train set R^2 is %.3f\" %(model1.score(X_train, y_train)))\n",
    "print(\"The test set R^2 is %.3f\" %(model1.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "randomForest1 = ensemble.RandomForestRegressor()\n",
    "bagging = ensemble.BaggingClassifier()\n",
    "\n",
    "randomForest1.set_params(random_state=42, n_estimators=464, max_features=4, min_samples_split=8)\n",
    "\n",
    "print(randomForest1.fit(X_train,y_train))\n",
    "\n",
    "print(randomForest1.score(X_train,y_train))\n",
    "randomForest1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Residuals Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = pd.DataFrame(y - randomForest1.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(randomForest1.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted.rename(columns={0: \"Predicted\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = residuals.rename(columns={\"SalePrice\": \"Residual Values\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = clean_df[['SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_actual = pd.concat([residuals, g], axis=1, sort=False)\n",
    "resid_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# absolute residual values vs sale price graph\n",
    "\n",
    "sns.scatterplot(x=resid_actual['SalePrice'], y=resid_actual['Residual Values'], data=resid_actual).set_title \\\n",
    "('Random Forest Residuals Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_actual = pd.concat([predicted, g], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted vs. actual sale price values plot \n",
    "\n",
    "sns.scatterplot(x=predicted_actual['SalePrice'], y=predicted_actual['Predicted'], data=predicted_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphviz - Getting Image of Decision Tree from Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = randomForest1.estimators_[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = X.columns,\n",
    "                class_names = 'SalePrice',\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model2 = ExtraTreesClassifier()\n",
    "model2.fit(X,y)\n",
    "print(model2.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model2.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(55).plot(kind='barh', figsize=(6,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_pickle('./data/clean_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
